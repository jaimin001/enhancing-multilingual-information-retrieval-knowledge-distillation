# Enhancing Multilingual Information Retrieval with Reranking using Mono-Language Sentence Embeddings and Knowledge Distillation

In this project, a multilingual reranking pipeline is being developed using Mono-language sentence embeddings and knowledge distillation. The first step involves creating models for cross language sentence embeddings using knowledge distillation techniques. Then this sentence embedding models are used to create the Multilingual Biencoder structures which in turn as used for reranking.

## Methodology

1. `Sentence Comparison`: The pipeline aims to compare sentences in multiple languages (English, German, Arabic) with a query sentence in English. This involves using a biencoder approach, which utilizes different types of biencoders (En-En, En-De, En-Ar) to compare sentences within their respective language pairs.
2. `Biencoder Approach`: The biencoder approach involves employing separate biencoders for each language pair (e.g., English-English, English-German, English-Arabic). These biencoders are used to encode sentences and generate embeddings. The embeddings are then used to compute similarity scores between sentences, enabling sentence comparison across languages.
3. `Knowledge Distillation and Mean Pooling`: To ensure that the scores generated by the embedding generating BERT models are comparable, the models are trained using knowledge distillation. This process involves transferring knowledge from a teacher model to a student model. Additionally, mean pooling is employed as a method to aggregate the embeddings and produce a single representation for each sentence pair. This facilitates a standardized approach for comparing sentences across different language pairs.

<img src="images/1.png" width="60%"></img> <img src="images/2.png" width="35%"></img>

### Contributors

-   Jaimin Gajjar
-   Saurabh Modi
-   Mukul Shingwani
